# AI via FastAI



Table of contents:

1. TOC
{:toc}


## What is FastAI
[Fast.ai](https://www.fast.ai/about.html) is an open-source library built on [pytorch](https://pytorch.org/), [blog](https://www.fast.ai/), [forum](https://forums.fast.ai/) and [educational platform](https://www.fast.ai/#category=courses) focused on making deep learning.

The course the most helped me understand about deep learning was [Practical Deep Learning for Coders 2022](https://www.fast.ai/posts/2022-07-21-dl-coders-22.html) taught by Jeremy Howard and based on a freely available [book](https://github.com/fastai/fastbook/).

Although I have not yet been through all 8 lessons I have made progress on the following:

- [x] Getting started
- [x] Deployment
- [x] Neural net foundations
- [ ] Natural Language (NLP)
- [ ] From-scratch model
- [ ] Random forests
- [ ] Collaborative filtering and embeddings
- [ ] Convolutions (CNNs)

## Training set and Testing set
With any machine leanring there needs to be 2 sets of data to devlop and train the model on. One to train the model and update the weightings and the other to validate the model.

To make sure the model isint being validated with a training set 1 set of data* is input into DataBlock() with data loaded from dataloaders() please see below[^1]:


```python
dls = DataBlock(
    blocks=(ImageBlock, CategoryBlock), 
    get_items=get_image_files, 
    splitter=RandomSplitter(valid_pct=0.2, seed=42),
    get_y=parent_label,
    item_tfms=[Resize(192, method='squish')]
).dataloaders(path, bs=16)
```
{% include alert.html text="user will need to confirm duplicates arent loaded into this dataset" %}

The above code using the *splitter* option in DataBlock() sets the validation set to *valid_pc* 0.2 (20%)  of the dataset randomly sampled with *seed* 42

## resnet18
One primary concept used from the fastAi library is resnet18 from the [vision_learner](https://docs.fast.ai/vision.learner.html) function.

ResNet-18 is a convolutional neural network (CNN) architecture from the Residual Network family, introduced in "Deep Residual Learning for Image Recognition" by Kaiming He et al. It enabled users to train **deep** networks without the vanishing gradient problem. This is utilised in my assignment 2 of ELEC4630.

Note: Vanishing gradient is where the gradients become extremely small during backpropogation causing the network to learn very slowly or stop learning.

it is implemented using code below[^1] where the architecrture is set as resnet18, dataset dls and does 3 iterations to optimise the model. 
```python
learn = vision_learner(dls, resnet18, metrics=error_rate)
learn.fine_tune(3)
```

## Footnotes

[^1]: Code is based on 00-is-it-a-bird-creating-a-model-from-your-own-data

